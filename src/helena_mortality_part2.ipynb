{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from joblib import Parallel, delayed\n",
    "from statistics import mode\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import rioxarray\n",
    "\n",
    "from xrspatial import focal, slope\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from joblib_progress import joblib_progress\n",
    "from xrspatial.multispectral import ndvi, savi\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (confusion_matrix, ConfusionMatrixDisplay)\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV as RSCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "helena_path = Path.cwd().parent / 'data' / 'helena'\n",
    "feature_dir = helena_path / 'features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get paths for features using 100 m geomorphons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the model which was tuned and trained in `src/mortality_classification.ipynb`.  It was pickled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model created in src/mortality_classification.ipynb\n",
    "pickle_path = Path.cwd() / 'RF_model.sav'\n",
    "model = pickle.load(open(pickle_path, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will make model predictions for the samples and create a timeseries of survival probabilities for each sample over the years for which we have NAIP data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_keys = dict_of_samples.keys()\n",
    "geomorphon_keys = range(1,11)\n",
    "years = [2018, 2020, 2022]\n",
    "\n",
    "for tk in treatment_keys:\n",
    "    for gk in geomorphon_keys:\n",
    "        ...\n",
    "def sample_mortality_timeseries(sample_dict, years):\n",
    "    '''\n",
    "    Takes a dict of years for a given sample,\n",
    "    returns a df of probabilities of being alive\n",
    "    by year.\n",
    "    '''\n",
    "    t_series = []\n",
    "    for y in years:\n",
    "        cols = sample_dict[y].drop(['y', 'label', 'UniqueID'], axis=1).columns\n",
    "        X = sample_dict[y][cols]\n",
    "        lil_df = pd.DataFrame()\n",
    "        lil_df['UniqueID'] = sample_dict[y]['UniqueID']\n",
    "        lil_df['pred'] = model.predict_proba(X)[:, 1]\n",
    "        t_series.append(lil_df)\n",
    "        \n",
    "    t_series = [t_series[0].join(df_, on='UniqueID') for df_ in t_series[1:]][0]\n",
    "        \n",
    "    return t_series\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "treemort",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
