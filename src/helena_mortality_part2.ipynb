{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we make predictions for all of the crowns which have treatment and geopmorphon information attached.  We will then attach the predictions to the crown df and save to `/TreeMortality/data/helena/predictions.parquet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from joblib import Parallel, delayed\n",
    "from statistics import mode\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import rioxarray\n",
    "\n",
    "from xrspatial import focal, slope\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from joblib_progress import joblib_progress\n",
    "from xrspatial.multispectral import ndvi, savi\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (confusion_matrix, ConfusionMatrixDisplay)\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV as RSCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "helena_path = Path.cwd().parent / 'data' / 'helena'\n",
    "feature_dir = helena_path / 'features'\n",
    "crowns_path = helena_path / 'spectral_crowns' / 'crowns.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2018: [PosixPath('/home/michael/TreeMortality/data/helena/features/features_2018_1.parquet'),\n",
       "  PosixPath('/home/michael/TreeMortality/data/helena/features/features_2018_2.parquet'),\n",
       "  PosixPath('/home/michael/TreeMortality/data/helena/features/features_2018_4.parquet'),\n",
       "  PosixPath('/home/michael/TreeMortality/data/helena/features/features_2018_10.parquet'),\n",
       "  PosixPath('/home/michael/TreeMortality/data/helena/features/features_2018_8.parquet'),\n",
       "  PosixPath('/home/michael/TreeMortality/data/helena/features/features_2018_3.parquet'),\n",
       "  PosixPath('/home/michael/TreeMortality/data/helena/features/features_2018_6.parquet'),\n",
       "  PosixPath('/home/michael/TreeMortality/data/helena/features/features_2018_11.parquet'),\n",
       "  PosixPath('/home/michael/TreeMortality/data/helena/features/features_2018_7.parquet'),\n",
       "  PosixPath('/home/michael/TreeMortality/data/helena/features/features_2018_5.parquet'),\n",
       "  PosixPath('/home/michael/TreeMortality/data/helena/features/features_2018_9.parquet')],\n",
       " 2020: [PosixPath('/home/michael/TreeMortality/data/helena/features/features_2020_1.parquet')],\n",
       " 2022: [PosixPath('/home/michael/TreeMortality/data/helena/features/features_2022_1.parquet')]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# years we will be looking at\n",
    "years = [2018, 2020, 2022]\n",
    "\n",
    "# get paths for features for years\n",
    "parquets = {}\n",
    "for y in years:\n",
    "    parquets[y] = [feature_dir / p for p in os.listdir(feature_dir) if f'features_{y}_' in p]\n",
    "\n",
    "\n",
    "parquets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the model which was tuned and trained in `src/mortality_classification.ipynb`.  It was pickled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model created in src/mortality_classification.ipynb\n",
    "pickle_path = Path.cwd() / 'RF_model.sav'\n",
    "model = pickle.load(open(pickle_path, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will make model predictions for the samples and create a timeseries of survival probabilities for each sample over the years for which we have NAIP data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------features_2018_crowns_100.parquet----------\n",
      "-------features_2020_crowns_100.parquet----------\n",
      "-------features_2022_crowns_100.parquet----------\n"
     ]
    }
   ],
   "source": [
    "pred_list = []\n",
    "for y in years:   \n",
    "    \n",
    "    # read parquet\n",
    "    df = pd.concat(\n",
    "    pd.read_parquet(parquet_file)\n",
    "    for parquet_file in parquets[y]\n",
    "    )\n",
    "    \n",
    "    # make input features, X\n",
    "    cols = list(model.feature_names_in_)\n",
    "    X = df[cols]\n",
    "    \n",
    "    # make predictions\n",
    "    pred = pd.DataFrame()\n",
    "    pred['UniqueID'] = df['UniqueID']\n",
    "    pred[f'pred_{y}'] = model.predict_proba(X)[:, 1]\n",
    "    pred = pred.set_index('UniqueID')\n",
    "    pred_list.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join all years into one df\n",
    "pred_df = pd.concat(pred_list, axis=1)\n",
    "\n",
    "# open desired columns of crowns\n",
    "crowns = gpd.read_parquet(crowns_path)[[\n",
    "    'UniqueID',\n",
    "    'area',\n",
    "    'zq95',\n",
    "    'treatment',\n",
    "    'geomorph_100',\n",
    "    'geomorph_250',\n",
    "    'geomorph_500',\n",
    "    'geomorph_1000',\n",
    "    'geomorph_2000',\n",
    "    'geometry'\n",
    "]].set_index('UniqueID')\n",
    "\n",
    "# join crowns to predictions and move unique id back to a column\n",
    "crowns = pd.concat([crowns, pred_df], axis=1).reset_index()\n",
    "\n",
    "print(len(crowns), ' crowns.')\n",
    "crowns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "crowns.to_parquet(helena_path / 'predictions.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "treemort",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
