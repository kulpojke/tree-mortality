{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import rioxarray\n",
    "\n",
    "from xrspatial import hillshade\n",
    "from xrspatial import convolution\n",
    "from datashader.colors import Set1\n",
    "from datashader.transfer_functions import shade\n",
    "from datashader.transfer_functions import stack\n",
    "from datashader.transfer_functions import dynspread\n",
    "from datashader.transfer_functions import set_background\n",
    "from datashader.colors import Elevation\n",
    "\n",
    "from xrspatial import focal, slope\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from joblib_progress import joblib_progress\n",
    "from xrspatial.multispectral import ndvi, savi\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (confusion_matrix, ConfusionMatrixDisplay)\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV as RSCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "high_high_path = '/home/michael/TreeMortality/data/helena/treatment_polys/code15_n5.gpkg'\n",
    "high_un_path = '/home/michael/TreeMortality/data/helena/treatment_polys/code12_n5.gpkg'\n",
    "un_high_path = '/home/michael/TreeMortality/data/helena/treatment_polys/code3_n5.gpkg'\n",
    "un_un_path = '/home/michael/TreeMortality/data/helena/treatment_polys/code0_n5.gpkg'\n",
    "poly_paths = [high_high_path, high_un_path, un_high_path, un_un_path]\n",
    "\n",
    "helena_path = Path.cwd().parent / 'data' / 'helena'\n",
    "crown_path = helena_path / 'crowns'\n",
    "crown_path_list = [\n",
    "    c for c\n",
    "    in crown_path.iterdir()\n",
    "    if c.suffix == '.gpkg'\n",
    "    ]\n",
    "\n",
    "# open treatment polygons\n",
    "df = pd.concat([gpd.read_file(p) for p in poly_paths])\n",
    "df = df.drop('area_', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first check each crown to see if it falls completely within one of the treatment class areas.  If so it will be appended to a datframe of crowns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jobs to run in ||\n",
    "n_jobs = 23\n",
    "\n",
    "def is_in_treatment(crown_df, row, buf):\n",
    "    '''Returns only crowns with buffer completely within polygon'''\n",
    "    crown_df.loc[\n",
    "        buf.within(row.geometry),\n",
    "        'treatment'] = row.attribute\n",
    "    \n",
    "    return crown_df[crown_df.treatment >= 0 ]\n",
    "\n",
    "\n",
    "def label_treatment(f):\n",
    "    crown_df = gpd.read_file(f)\n",
    "    \n",
    "    # get total bounds of tile as polygon\n",
    "    bounds = crown_df.total_bounds\n",
    "    bbox = shapely.geometry.box(*bounds)\n",
    "\n",
    "    # use only treatment geometries which touch the tile\n",
    "    sub_df = df[df.geometry.intersects(bbox)]\n",
    "    if len(sub_df) > 0:\n",
    "        # add treatment column\n",
    "        crown_df['treatment'] = -99\n",
    "        #buffer crowns\n",
    "        buf = crown_df.geometry.buffer(10)\n",
    "        # label treatments of crowns lying completely within poly\n",
    "        return Parallel(n_jobs=n_jobs)(\n",
    "            delayed(is_in_treatment)(crown_df, row, buf)\n",
    "            for _, row in sub_df.iterrows()\n",
    "            )\n",
    "    else:\n",
    "        # return empty df, but add treatment column first\n",
    "        cols = list(crown_df.columns) + ['treatment']\n",
    "        empty_df = pd.DataFrame(columns=cols)\n",
    "        return [empty_df]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f996a7f9d7214fc8a74c6b061bb5002b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with joblib_progress('', total=len(crown_path_list)):\n",
    "    results =  Parallel(n_jobs=n_jobs)(delayed(label_treatment)(f) for f in crown_path_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results is a list of lists of dfs, so we must flatten to concat\n",
    "crown_df = pd.concat([item for sublist in results for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "results = [label_treatment(f) for f in tqdm(crown_path_list)]\n",
    "crown_df = pd.concat(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we will also add a unique identifier.  Then save `crowns_df` so in case ware interrupted,  we will be able to resume without running the 5 hour block of code above again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDdalponte</th>\n",
       "      <th>zmax</th>\n",
       "      <th>zmean</th>\n",
       "      <th>zsd</th>\n",
       "      <th>zskew</th>\n",
       "      <th>zkurt</th>\n",
       "      <th>zentropy</th>\n",
       "      <th>pzabovezmean</th>\n",
       "      <th>pzabove2</th>\n",
       "      <th>zq5</th>\n",
       "      <th>...</th>\n",
       "      <th>p2th</th>\n",
       "      <th>p3th</th>\n",
       "      <th>p4th</th>\n",
       "      <th>p5th</th>\n",
       "      <th>pground</th>\n",
       "      <th>n</th>\n",
       "      <th>area</th>\n",
       "      <th>geometry</th>\n",
       "      <th>treatment</th>\n",
       "      <th>UniqueID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.29</td>\n",
       "      <td>4.970000</td>\n",
       "      <td>0.549181</td>\n",
       "      <td>-1.123796</td>\n",
       "      <td>2.307702</td>\n",
       "      <td>0.313845</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.3030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0672</td>\n",
       "      <td>POLYGON ((496566.730 4511249.660, 496566.620 4...</td>\n",
       "      <td>12</td>\n",
       "      <td>10N_496567_4511250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.93</td>\n",
       "      <td>5.684000</td>\n",
       "      <td>0.387337</td>\n",
       "      <td>-1.405252</td>\n",
       "      <td>3.124655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.1560</td>\n",
       "      <td>...</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>POLYGON ((496570.930 4511249.740, 496570.640 4...</td>\n",
       "      <td>12</td>\n",
       "      <td>10N_496571_4511250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>9.26</td>\n",
       "      <td>7.120000</td>\n",
       "      <td>2.037727</td>\n",
       "      <td>-0.419361</td>\n",
       "      <td>1.899452</td>\n",
       "      <td>0.602060</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.8005</td>\n",
       "      <td>...</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0638</td>\n",
       "      <td>POLYGON ((496589.250 4511249.710, 496589.000 4...</td>\n",
       "      <td>12</td>\n",
       "      <td>10N_496589_4511250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>13.39</td>\n",
       "      <td>11.101111</td>\n",
       "      <td>1.725648</td>\n",
       "      <td>0.357462</td>\n",
       "      <td>1.321602</td>\n",
       "      <td>0.435405</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9.4440</td>\n",
       "      <td>...</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1551</td>\n",
       "      <td>POLYGON ((496743.460 4511249.750, 496743.330 4...</td>\n",
       "      <td>12</td>\n",
       "      <td>10N_496743_4511250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>9.49</td>\n",
       "      <td>6.605000</td>\n",
       "      <td>2.987673</td>\n",
       "      <td>-0.013348</td>\n",
       "      <td>1.025824</td>\n",
       "      <td>0.439247</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.6300</td>\n",
       "      <td>...</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1148</td>\n",
       "      <td>POLYGON ((496775.400 4511249.590, 496775.330 4...</td>\n",
       "      <td>12</td>\n",
       "      <td>10N_496775_4511250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   IDdalponte   zmax      zmean       zsd     zskew     zkurt  zentropy  \\\n",
       "0         2.0   5.29   4.970000  0.549181 -1.123796  2.307702  0.313845   \n",
       "1         3.0   5.93   5.684000  0.387337 -1.405252  3.124655  0.000000   \n",
       "2         4.0   9.26   7.120000  2.037727 -0.419361  1.899452  0.602060   \n",
       "3        10.0  13.39  11.101111  1.725648  0.357462  1.321602  0.435405   \n",
       "4        11.0   9.49   6.605000  2.987673 -0.013348  1.025824  0.439247   \n",
       "\n",
       "   pzabovezmean  pzabove2     zq5  ...       p2th       p3th  p4th  p5th  \\\n",
       "0     75.000000     100.0  4.3030  ...   0.000000   0.000000   0.0   0.0   \n",
       "1     80.000000     100.0  5.1560  ...  20.000000   0.000000   0.0   0.0   \n",
       "2     50.000000     100.0  4.8005  ...  25.000000   0.000000   0.0   0.0   \n",
       "3     44.444444     100.0  9.4440  ...  44.444444   0.000000   0.0   0.0   \n",
       "4     50.000000     100.0  3.6300  ...  50.000000  16.666667   0.0   0.0   \n",
       "\n",
       "   pground  n    area                                           geometry  \\\n",
       "0      0.0  4  0.0672  POLYGON ((496566.730 4511249.660, 496566.620 4...   \n",
       "1      0.0  5  0.0760  POLYGON ((496570.930 4511249.740, 496570.640 4...   \n",
       "2      0.0  4  0.0638  POLYGON ((496589.250 4511249.710, 496589.000 4...   \n",
       "3      0.0  9  0.1551  POLYGON ((496743.460 4511249.750, 496743.330 4...   \n",
       "4      0.0  6  0.1148  POLYGON ((496775.400 4511249.590, 496775.330 4...   \n",
       "\n",
       "   treatment            UniqueID  \n",
       "0         12  10N_496567_4511250  \n",
       "1         12  10N_496571_4511250  \n",
       "2         12  10N_496589_4511250  \n",
       "3         12  10N_496743_4511250  \n",
       "4         12  10N_496775_4511250  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_unique_ID(crowns, utm_zone):\n",
    "    '''\n",
    "    returns copy of dataframe with new uniqueID column\n",
    "    with entries of form 'utm_zone_x_y where x and y \n",
    "    are rounded to the nearest meter.\n",
    "    TODO: make it round to nearest even meter to lower precision\n",
    "    '''\n",
    "    crowns['UniqueID'] = crowns.geometry.centroid.apply(\n",
    "        lambda p: f'{utm_zone}_{p.x:.0f}_{p.y:.0f}')\n",
    "    \n",
    "    return crowns\n",
    "\n",
    "# add unique ID\n",
    "crown_df_ = make_unique_ID(crown_df, '10N')\n",
    "crown_df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "crown_df_.to_file(helena_path / 'crowns_with_treatment_label.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "treatment\n",
       "0     2794929\n",
       "3      601844\n",
       "12     468077\n",
       "15      11980\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure the number of treatments is reasonable\n",
    "crown_df_.treatment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now finally we kno is safe to make crown_df = crown_df_ \n",
    "crown_df = crown_df_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topographic Position Index\n",
    "In order to look at the effects of slope position on tree mortality we will use an algorithm that replicates the Topographic Position Index (TPI). \n",
    "\n",
    "$$\n",
    "\\text{TPI} = round((\\text{DEM} - \\text{focalmean}(\\text{DEM}, \\;annulus)) + 0.5)\n",
    "$$\n",
    "where _annulus_ is an anuulus defined by an inner and outer radius $, r_{inner}$ and $r_{outer}$, \n",
    "In keeping consistent with the methods of Kane et al.\\cite{kane2015} we will use $r_{outer}$ of 100 m, 250 m, 500 m, 1000 m, and 2000 m outer radii. Since the authors do not specify the inner radius used, here we will use the rule that $r_{inner} = \\frac{r_{outer}}{2}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the DEM\n",
    "dem = rioxarray.open_rasterio(helena_path / 'helena_DEM.tif')\n",
    "slope_agg = slope(dem[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def topographic_position_index(dem, outer_radius, res=1):\n",
    "    '''\n",
    "    returns topological position index\n",
    "    using r_inner = r_outer /2\n",
    "    '''\n",
    "    inner_radius = round(outer_radius / 2)\n",
    "    kernel = convolution.annulus_kernel(res, res, outer_radius, inner_radius)\n",
    "    return dem - focal.apply(dem, kernel)\n",
    "\n",
    "tpi = topographic_position_index(dem[0], 100)\n",
    "tpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpi_terrain = hillshade(tpi)\n",
    "tpi_terrain_shaded = shade(\n",
    "    tpi_terrain, cmap=[\"white\", \"black\"], alpha=255, how=\"linear\"\n",
    ")\n",
    "illuminated = hillshade(dem)\n",
    "illuminated_shaded = shade(illuminated, cmap=['gray', 'white'], alpha=255, how='linear')\n",
    "stack(illuminated_shaded, tpi_terrain_shaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slope_position(tpi, slope):\n",
    "    std_dev = tpi.std()\n",
    "    arr = tpi.to_numpy()\n",
    "    slope_pos = np.zeros_like(arr)\n",
    "    \n",
    "    # class description breakpoints\n",
    "    slope_pos[arr > std_dev] = 1 # ridge\n",
    "    slope_pos[0.5 * std_dev < arr <= std_dev] = 2 # upper slope\n",
    "    slope_pos[(-0.5 * std_dev < arr < 0.5 * std_dev) & (slope_agg > 5)] = 3  # middle slope\n",
    "    slope_pos[(-0.5 * std_dev < arr < 0.5 * std_dev)  & (slope_agg <= 5)] = 4  # flats slope\n",
    "    slope_pos[-std_dev < arr < -0.5 * std_dev] = 5 # lower slope\n",
    "    slope_pos[arr < -std_dev] = 6 # valleys\n",
    "    \n",
    "    # numpy --> dataArray\n",
    "    dset = tpi.to_dataset(name='whatever')\n",
    "    dset['slope_pos'] = (('y', 'x'), slope_pos)\n",
    "    return dset.slope_pos\n",
    "\n",
    "slope_pos = slope_position(tpi, slope)\n",
    "slope_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(helena_path / 'TPI')\n",
    "\n",
    "def inner_func(slope_pos, row):\n",
    "    zult = round(np.median(slope_pos.rio.clip([row.geometry]).to_numpy()))\n",
    "    return (row.UniqueID, zult)\n",
    "\n",
    "results = []\n",
    "\n",
    "for r in tqdm([100, 250, 500, 1000, 2000]):\n",
    "    # add column full of no data vals\n",
    "    crown_df[f'slope_position_{r}'] = -999\n",
    "    \n",
    "    # calc tpi and slope position\n",
    "    tpi = topographic_position_index(dem, r)\n",
    "    slope_pos = slope_position(tpi, slope)\n",
    "    \n",
    "    # save as tiffs\n",
    "    tpi.rio.to_raster(helena_path / 'TPI' / f'tpi_{r}.tif')\n",
    "    slope_pos.rio.to_raster(helena_path / 'TPI' / f'slope_pos_{r}.tif')\n",
    "\n",
    "    # free a little memory    \n",
    "    del tpi\n",
    "\n",
    "    # attach slope positions to crowns\n",
    "    results.append(\n",
    "        pd.DataFrame(\n",
    "            Parallel(n_jobs=n_jobs)(\n",
    "                delayed(inner_func)(slope_pos, row)\n",
    "                for _, row in crown_df.iterrows()\n",
    "            ),\n",
    "            columns=['UniqueID', f'slope_position_{r}']\n",
    "        )\n",
    "    )\n",
    "\n",
    "# join all results on UniqueID\n",
    "for data_frame_thing in results:\n",
    "    crown_df = crown_df.join(\n",
    "        data_frame_thing,\n",
    "        on='UniqueID'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in [100, 250, 500, 1000, 2000]:\n",
    "    ...\n",
    "    # calculate TPI\n",
    "    \n",
    "    # make sample stratified by treatment and TPI class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create a two-level stratified sample of crowns based on treatment and TPI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict to hold samples\n",
    "dict_of_samples = {}\n",
    "\n",
    "# split into groups based on treatment\n",
    "for tr in [0, 3, 12, 15]:\n",
    "    df_x = crown_df[crown_df.treatment == tr]\n",
    "\n",
    "    # for each treatment, split based on slope position.\n",
    "    sub_dict = {}\n",
    "    for pos in [1, 2, 3, 4, 5, 6]:\n",
    "        sub_dict[f'slope_position_{r}'] = df_x[df_x[f'slope_position_{r}'] == pos]\n",
    "    dict_of_samples[f'treatment_{tr}'] = sub_dict\n",
    "\n",
    "# get largest possible even sample for each treatment\n",
    "for key1, val_dict in dict_of_samples.items():\n",
    "    # get smallest  TPI population for given treatment\n",
    "    n = min([len(d) for d in val_dict[key1]])\n",
    "    # now sample each to that size\n",
    "    for key2, val in val_dict.items():\n",
    "        dict_of_samples[key1][key2] = dict_of_samples[key1][key2].sample(n=n)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to engineer the features for our model, as done in `src/mortality_classification_geographic_holdouts.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "treemort",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
